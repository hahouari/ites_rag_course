{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Chatbot linked to the Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: surrealdb==1.0.3 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (1.0.3)\n",
      "Requirement already satisfied: openai==1.55.2 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (1.55.2)\n",
      "Requirement already satisfied: python-dotenv==1.0.1 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: Cerberus==1.3.7 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from surrealdb==1.0.3) (1.3.7)\n",
      "Requirement already satisfied: aiohappyeyeballs==2.4.4 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from surrealdb==1.0.3) (2.4.4)\n",
      "Requirement already satisfied: aiohttp==3.11.11 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from surrealdb==1.0.3) (3.11.11)\n",
      "Requirement already satisfied: aiosignal==1.3.2 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from surrealdb==1.0.3) (1.3.2)\n",
      "Requirement already satisfied: async-timeout==5.0.1 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from surrealdb==1.0.3) (5.0.1)\n",
      "Requirement already satisfied: attrs==25.1.0 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from surrealdb==1.0.3) (25.1.0)\n",
      "Requirement already satisfied: cbor2==5.6.5 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from surrealdb==1.0.3) (5.6.5)\n",
      "Requirement already satisfied: certifi==2024.12.14 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from surrealdb==1.0.3) (2024.12.14)\n",
      "Requirement already satisfied: charset-normalizer==3.4.1 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from surrealdb==1.0.3) (3.4.1)\n",
      "Requirement already satisfied: frozenlist==1.5.0 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from surrealdb==1.0.3) (1.5.0)\n",
      "Requirement already satisfied: idna==3.10 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from surrealdb==1.0.3) (3.10)\n",
      "Requirement already satisfied: marshmallow==3.26.0 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from surrealdb==1.0.3) (3.26.0)\n",
      "Requirement already satisfied: multidict==6.1.0 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from surrealdb==1.0.3) (6.1.0)\n",
      "Requirement already satisfied: packaging==24.2 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from surrealdb==1.0.3) (24.2)\n",
      "Requirement already satisfied: propcache==0.2.1 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from surrealdb==1.0.3) (0.2.1)\n",
      "Requirement already satisfied: pytz==2024.2 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from surrealdb==1.0.3) (2024.2)\n",
      "Requirement already satisfied: requests==2.32.3 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from surrealdb==1.0.3) (2.32.3)\n",
      "Requirement already satisfied: typing_extensions==4.12.2 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from surrealdb==1.0.3) (4.12.2)\n",
      "Requirement already satisfied: urllib3==2.3.0 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from surrealdb==1.0.3) (2.3.0)\n",
      "Requirement already satisfied: websockets==14.2 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from surrealdb==1.0.3) (14.2)\n",
      "Requirement already satisfied: yarl==1.18.3 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from surrealdb==1.0.3) (1.18.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from openai==1.55.2) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from openai==1.55.2) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from openai==1.55.2) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from openai==1.55.2) (0.8.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from openai==1.55.2) (2.10.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from openai==1.55.2) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from openai==1.55.2) (4.67.1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from httpx<1,>=0.23.0->openai==1.55.2) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.55.2) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from pydantic<3,>=1.9.0->openai==1.55.2) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from pydantic<3,>=1.9.0->openai==1.55.2) (2.27.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from tqdm>4->openai==1.55.2) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install surrealdb==1.0.3 openai==1.55.2 python-dotenv==1.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surrealdb import Surreal\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Connect to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "surrealdb-2.2.0\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(override=True)\n",
    "\n",
    "db = Surreal(os.getenv(\"SURREAL_URL\"))\n",
    "db.signin({\"username\": os.getenv(\"SURREAL_USER\"), \"password\": os.getenv(\"SURREAL_PASS\")})\n",
    "db.use(os.getenv(\"SURREAL_NAMESPACE\"), os.getenv(\"SURREAL_DATABASE\"))\n",
    "\n",
    "print(db.version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Embed articles and save to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```context\n",
      "المادة 2 : الإسلام  دين الدّولة.\n",
      "المادة 10 : لا يجوز للمؤسّسات أن تقوم بما يأتي : - الممارسات الإقطاعيّة، والجهويّة، والمحسوبيّة، - إقامة علاقات الاستغلال والتّبعيّة، - السّلوك المخالف للخُلُق الإسلاميّ وقيم ثورة نوفمبر.\n",
      "المادة 76  : على كلّ مواطن أن يؤدّي بإخلاص واجباته تجاه المجموعة الوطنيّة. التزام المواطن إزاء الوطن وإجباريّة المشاركة في الدّفاع عنه، واجبان مقدّسان دائمان. تضمن الدّولة احترام رموز الثّورة، وأرواح الشّهداء، وكرامة ذويهم، والمجاهدين. وتعمل كذلك على ترقية كتابة التاريخ وتعليمه للأجيال الناشئة.\n",
      "المادة 30 : الجزائر متضامنة مع جميع الشّعوب الّتي تكافح من أجل التّحرّر السّياسيّ والاقتصاديّ، والحقّ             في تقرير المصير، وضدّ كلّ تمييز عنصريّ.\n",
      "المادة 31 : تعمل الجزائر من أجل دعم التّعاون الدّوليّ، وتنمية العلاقات الودّيّة بين الدّول، على أساس المساواة، والمصلحة المتبادلة، وعدم التّدخّل في الشّؤون الدّاخليّة. وتتبنّى مبادئ ميثاق الأمم المتّحدة وأهدافه.\n",
      "```\n",
      "```question\n",
      "if I'm christian, what should I do in Algeria? and give me brief answer\n",
      "```\n",
      "\n",
      "------------------\n",
      "\n",
      "لا يمكنني الإجابة عن السؤال بناءً على السياق المتوفر."
     ]
    }
   ],
   "source": [
    "client = OpenAI() # api key loaded from .env\n",
    "embed_model_name = \"text-embedding-3-small\"\n",
    "llm_model_name = \"gpt-4o\"\n",
    "system_prompt = \"\"\"\n",
    "You are an Algerian legal expert AI trained to provide accurate answers.\n",
    "You must strictly base your answer on the provided context.\n",
    "You must avoid at all cost to mention in your answer that you are being provided with context.\n",
    "You must strictly answer in Arabic.\n",
    "Translate the keywords from context to Arabic.\n",
    "Your response must adhere to any requested format in the question, if present.\n",
    "Interpret the context to extract required information and present it directly, without mentioning the reasoning process.\n",
    "If not, state clearly that you are unable to answer the question.\n",
    "Do not fabricate or assume facts.\n",
    "\"\"\".strip()\n",
    "\n",
    "def search_articles(query):\n",
    "    response = client.embeddings.create(\n",
    "        input=query,\n",
    "        model=embed_model_name,\n",
    "    )\n",
    "    q_vector = response.data[0].embedding\n",
    "\n",
    "    results = db.query(\"\"\"\n",
    "        SELECT\n",
    "            text,\n",
    "            vector::similarity::cosine(embed_vector, $q_vector) AS score\n",
    "        FROM articles\n",
    "        ORDER BY score DESC\n",
    "        LIMIT 5\n",
    "        \"\"\",\n",
    "        {\"q_vector\": q_vector}\n",
    "    )\n",
    "\n",
    "    return results\n",
    "\n",
    "def ask_question(query):\n",
    "    articles = search_articles(query)\n",
    "\n",
    "    user_prompt = \"```context\\n\"\n",
    "    for article in articles:\n",
    "        user_prompt += f\"{article['text']}\\n\"\n",
    "    user_prompt += \"```\\n\"\n",
    "    user_prompt += f\"```question\\n{query}\\n```\"\n",
    "\n",
    "    print(user_prompt)\n",
    "    print(\"\\n------------------\\n\")\n",
    "\n",
    "    stream = client.chat.completions.create(\n",
    "        model=llm_model_name,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ],\n",
    "        stream=True,\n",
    "    )\n",
    "    \n",
    "    for chunk in stream:\n",
    "        text_chunk = chunk.choices[0].delta.content\n",
    "        if text_chunk is None:\n",
    "            continue\n",
    "        print(text_chunk, end=\"\")\n",
    "\n",
    "question = \"if I'm christian, what should I do in Algeria? and give me brief answer\"\n",
    "# question = \"Anything about family law\"\n",
    "# question = \"معلومات عن الانتخابات\"\n",
    "ask_question(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
