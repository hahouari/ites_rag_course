{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Algerian Constitution 2020 into SurrealDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv==1.0.1 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: surrealdb==1.0.3 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (1.0.3)\n",
      "Collecting openai==1.63.0\n",
      "  Downloading openai-1.63.0-py3-none-any.whl.metadata (27 kB)\n",
      "Requirement already satisfied: Cerberus==1.3.7 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from surrealdb==1.0.3) (1.3.7)\n",
      "Requirement already satisfied: aiohappyeyeballs==2.4.4 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from surrealdb==1.0.3) (2.4.4)\n",
      "Requirement already satisfied: aiohttp==3.11.11 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from surrealdb==1.0.3) (3.11.11)\n",
      "Requirement already satisfied: aiosignal==1.3.2 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from surrealdb==1.0.3) (1.3.2)\n",
      "Requirement already satisfied: async-timeout==5.0.1 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from surrealdb==1.0.3) (5.0.1)\n",
      "Requirement already satisfied: attrs==25.1.0 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from surrealdb==1.0.3) (25.1.0)\n",
      "Requirement already satisfied: cbor2==5.6.5 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from surrealdb==1.0.3) (5.6.5)\n",
      "Requirement already satisfied: certifi==2024.12.14 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from surrealdb==1.0.3) (2024.12.14)\n",
      "Requirement already satisfied: charset-normalizer==3.4.1 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from surrealdb==1.0.3) (3.4.1)\n",
      "Requirement already satisfied: frozenlist==1.5.0 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from surrealdb==1.0.3) (1.5.0)\n",
      "Requirement already satisfied: idna==3.10 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from surrealdb==1.0.3) (3.10)\n",
      "Requirement already satisfied: marshmallow==3.26.0 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from surrealdb==1.0.3) (3.26.0)\n",
      "Requirement already satisfied: multidict==6.1.0 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from surrealdb==1.0.3) (6.1.0)\n",
      "Requirement already satisfied: packaging==24.2 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from surrealdb==1.0.3) (24.2)\n",
      "Requirement already satisfied: propcache==0.2.1 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from surrealdb==1.0.3) (0.2.1)\n",
      "Requirement already satisfied: pytz==2024.2 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from surrealdb==1.0.3) (2024.2)\n",
      "Requirement already satisfied: requests==2.32.3 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from surrealdb==1.0.3) (2.32.3)\n",
      "Requirement already satisfied: typing_extensions==4.12.2 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from surrealdb==1.0.3) (4.12.2)\n",
      "Requirement already satisfied: urllib3==2.3.0 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from surrealdb==1.0.3) (2.3.0)\n",
      "Requirement already satisfied: websockets==14.2 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from surrealdb==1.0.3) (14.2)\n",
      "Requirement already satisfied: yarl==1.18.3 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from surrealdb==1.0.3) (1.18.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from openai==1.63.0) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from openai==1.63.0) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from openai==1.63.0) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from openai==1.63.0) (0.8.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from openai==1.63.0) (2.10.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from openai==1.63.0) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from openai==1.63.0) (4.67.1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from httpx<1,>=0.23.0->openai==1.63.0) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.63.0) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from pydantic<3,>=1.9.0->openai==1.63.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from pydantic<3,>=1.9.0->openai==1.63.0) (2.27.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\hahouari\\anaconda3\\envs\\rag_course\\lib\\site-packages (from tqdm>4->openai==1.63.0) (0.4.6)\n",
      "Downloading openai-1.63.0-py3-none-any.whl (472 kB)\n",
      "Installing collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.55.2\n",
      "    Uninstalling openai-1.55.2:\n",
      "      Successfully uninstalled openai-1.55.2\n",
      "Successfully installed openai-1.63.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install surrealdb==1.0.3 google-genai==1.2.0 python-dotenv==1.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from surrealdb import Surreal\n",
    "from google import genai\n",
    "import json\n",
    "import os\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file_path = os.path.join(\"json\", \"dz_consti_2020.json\")\n",
    "with open(json_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    constitution_data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Connect to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "surrealdb-2.2.0\n"
     ]
    }
   ],
   "source": [
    "db = Surreal(os.getenv(\"SURREAL_URL\"))\n",
    "db.signin({\"username\": os.getenv(\"SURREAL_USER\"), \"password\": os.getenv(\"SURREAL_PASS\")})\n",
    "db.use(os.getenv(\"SURREAL_NAMESPACE\"), os.getenv(\"SURREAL_DATABASE\"))\n",
    "\n",
    "print(db.version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Embed articles and save to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model(name='models/chat-bison-001', display_name='PaLM 2 Chat (Legacy)', description='A legacy text-only model optimized for chat conversations', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=4096, output_token_limit=1024, supported_actions=['generateMessage', 'countMessageTokens']), Model(name='models/text-bison-001', display_name='PaLM 2 (Legacy)', description='A legacy model that understands text and generates text as an output', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=8196, output_token_limit=1024, supported_actions=['generateText', 'countTextTokens', 'createTunedTextModel']), Model(name='models/embedding-gecko-001', display_name='Embedding Gecko', description='Obtain a distributed representation of a text.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1024, output_token_limit=1, supported_actions=['embedText', 'countTextTokens']), Model(name='models/gemini-1.0-pro-latest', display_name='Gemini 1.0 Pro Latest', description='The original Gemini 1.0 Pro model. This model will be discontinued on February 15th, 2025. Move to a newer Gemini version.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=30720, output_token_limit=2048, supported_actions=['generateContent', 'countTokens']), Model(name='models/gemini-1.0-pro', display_name='Gemini 1.0 Pro', description='The best model for scaling across a wide range of tasks', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=30720, output_token_limit=2048, supported_actions=['generateContent', 'countTokens']), Model(name='models/gemini-pro', display_name='Gemini 1.0 Pro', description='The best model for scaling across a wide range of tasks', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=30720, output_token_limit=2048, supported_actions=['generateContent', 'countTokens']), Model(name='models/gemini-1.0-pro-001', display_name='Gemini 1.0 Pro 001 (Tuning)', description='The original Gemini 1.0 Pro model version that supports tuning. Gemini 1.0 Pro will be discontinued on February 15th, 2025. Move to a newer Gemini version.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=30720, output_token_limit=2048, supported_actions=['generateContent', 'countTokens', 'createTunedModel']), Model(name='models/gemini-1.0-pro-vision-latest', display_name='Gemini 1.0 Pro Vision', description='The original Gemini 1.0 Pro Vision model version which was optimized for image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. Move to a newer Gemini version.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=12288, output_token_limit=4096, supported_actions=['generateContent', 'countTokens']), Model(name='models/gemini-pro-vision', display_name='Gemini 1.0 Pro Vision', description='The original Gemini 1.0 Pro Vision model version which was optimized for image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. Move to a newer Gemini version.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=12288, output_token_limit=4096, supported_actions=['generateContent', 'countTokens']), Model(name='models/gemini-1.5-pro-latest', display_name='Gemini 1.5 Pro Latest', description='Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=2000000, output_token_limit=8192, supported_actions=['generateContent', 'countTokens']), Model(name='models/gemini-1.5-pro-001', display_name='Gemini 1.5 Pro 001', description='Stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens, released in May of 2024.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=2000000, output_token_limit=8192, supported_actions=['generateContent', 'countTokens', 'createCachedContent']), Model(name='models/gemini-1.5-pro-002', display_name='Gemini 1.5 Pro 002', description='Stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens, released in September of 2024.', version='002', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=2000000, output_token_limit=8192, supported_actions=['generateContent', 'countTokens', 'createCachedContent']), Model(name='models/gemini-1.5-pro', display_name='Gemini 1.5 Pro', description='Stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens, released in May of 2024.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=2000000, output_token_limit=8192, supported_actions=['generateContent', 'countTokens']), Model(name='models/gemini-1.5-flash-latest', display_name='Gemini 1.5 Flash Latest', description='Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1000000, output_token_limit=8192, supported_actions=['generateContent', 'countTokens']), Model(name='models/gemini-1.5-flash-001', display_name='Gemini 1.5 Flash 001', description='Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in May of 2024.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1000000, output_token_limit=8192, supported_actions=['generateContent', 'countTokens', 'createCachedContent']), Model(name='models/gemini-1.5-flash-001-tuning', display_name='Gemini 1.5 Flash 001 Tuning', description='Version of Gemini 1.5 Flash that supports tuning, our fast and versatile multimodal model for scaling across diverse tasks, released in May of 2024.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=16384, output_token_limit=8192, supported_actions=['generateContent', 'countTokens', 'createTunedModel']), Model(name='models/gemini-1.5-flash', display_name='Gemini 1.5 Flash', description='Alias that points to the most recent stable version of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1000000, output_token_limit=8192, supported_actions=['generateContent', 'countTokens']), Model(name='models/gemini-1.5-flash-002', display_name='Gemini 1.5 Flash 002', description='Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in September of 2024.', version='002', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1000000, output_token_limit=8192, supported_actions=['generateContent', 'countTokens', 'createCachedContent']), Model(name='models/gemini-1.5-flash-8b', display_name='Gemini 1.5 Flash-8B', description='Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1000000, output_token_limit=8192, supported_actions=['createCachedContent', 'generateContent', 'countTokens']), Model(name='models/gemini-1.5-flash-8b-001', display_name='Gemini 1.5 Flash-8B 001', description='Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1000000, output_token_limit=8192, supported_actions=['createCachedContent', 'generateContent', 'countTokens']), Model(name='models/gemini-1.5-flash-8b-latest', display_name='Gemini 1.5 Flash-8B Latest', description='Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1000000, output_token_limit=8192, supported_actions=['createCachedContent', 'generateContent', 'countTokens']), Model(name='models/gemini-1.5-flash-8b-exp-0827', display_name='Gemini 1.5 Flash 8B Experimental 0827', description='Experimental release (August 27th, 2024) of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model. Replaced by Gemini-1.5-flash-8b-001 (stable).', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1000000, output_token_limit=8192, supported_actions=['generateContent', 'countTokens']), Model(name='models/gemini-1.5-flash-8b-exp-0924', display_name='Gemini 1.5 Flash 8B Experimental 0924', description='Experimental release (September 24th, 2024) of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model. Replaced by Gemini-1.5-flash-8b-001 (stable).', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1000000, output_token_limit=8192, supported_actions=['generateContent', 'countTokens']), Model(name='models/gemini-2.0-flash-exp', display_name='Gemini 2.0 Flash Experimental', description='Gemini 2.0 Flash Experimental', version='2.0', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=8192, supported_actions=['generateContent', 'countTokens', 'bidiGenerateContent']), Model(name='models/gemini-2.0-flash', display_name='Gemini 2.0 Flash', description='Gemini 2.0 Flash', version='2.0', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=8192, supported_actions=['generateContent', 'countTokens']), Model(name='models/gemini-2.0-flash-001', display_name='Gemini 2.0 Flash 001', description='Stable version of Gemini 2.0 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in January of 2025.', version='2.0', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=8192, supported_actions=['generateContent', 'countTokens']), Model(name='models/gemini-2.0-flash-lite-preview', display_name='Gemini 2.0 Flash-Lite Preview', description='Preview release (February 5th, 2025) of Gemini 2.0 Flash Lite', version='preview-02-05', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=8192, supported_actions=['generateContent', 'countTokens']), Model(name='models/gemini-2.0-flash-lite-preview-02-05', display_name='Gemini 2.0 Flash-Lite Preview 02-05', description='Preview release (February 5th, 2025) of Gemini 2.0 Flash Lite', version='preview-02-05', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=8192, supported_actions=['generateContent', 'countTokens']), Model(name='models/gemini-2.0-pro-exp', display_name='Gemini 2.0 Pro Experimental', description='Experimental release (February 5th, 2025) of Gemini 2.0 Pro', version='2.0', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=2097152, output_token_limit=8192, supported_actions=['generateContent', 'countTokens']), Model(name='models/gemini-2.0-pro-exp-02-05', display_name='Gemini 2.0 Pro Experimental 02-05', description='Experimental release (February 5th, 2025) of Gemini 2.0 Pro', version='2.0', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=2097152, output_token_limit=8192, supported_actions=['generateContent', 'countTokens']), Model(name='models/gemini-exp-1206', display_name='Gemini Experimental 1206', description='Experimental release (February 5th, 2025) of Gemini 2.0 Pro', version='2.0', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=2097152, output_token_limit=8192, supported_actions=['generateContent', 'countTokens']), Model(name='models/gemini-2.0-flash-thinking-exp-01-21', display_name='Gemini 2.0 Flash Thinking Experimental 01-21', description='Experimental release (January 21st, 2025) of Gemini 2.0 Flash Thinking', version='2.0-exp-01-21', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=65536, supported_actions=['generateContent', 'countTokens']), Model(name='models/gemini-2.0-flash-thinking-exp', display_name='Gemini 2.0 Flash Thinking Experimental 01-21', description='Experimental release (January 21st, 2025) of Gemini 2.0 Flash Thinking', version='2.0-exp-01-21', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=65536, supported_actions=['generateContent', 'countTokens']), Model(name='models/gemini-2.0-flash-thinking-exp-1219', display_name='Gemini 2.0 Flash Thinking Experimental', description='Gemini 2.0 Flash Thinking Experimental', version='2.0', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=65536, supported_actions=['generateContent', 'countTokens']), Model(name='models/learnlm-1.5-pro-experimental', display_name='LearnLM 1.5 Pro Experimental', description='Alias that points to the most recent stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=32767, output_token_limit=8192, supported_actions=['generateContent', 'countTokens']), Model(name='models/embedding-001', display_name='Embedding 001', description='Obtain a distributed representation of a text.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=2048, output_token_limit=1, supported_actions=['embedContent']), Model(name='models/text-embedding-004', display_name='Text Embedding 004', description='Obtain a distributed representation of a text.', version='004', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=2048, output_token_limit=1, supported_actions=['embedContent']), Model(name='models/aqa', display_name='Model that performs Attributed Question Answering.', description='Model trained to return answers to questions that are grounded in provided sources, along with estimating answerable probability.', version='001', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=7168, output_token_limit=1024, supported_actions=['generateAnswer']), Model(name='models/imagen-3.0-generate-002', display_name='Imagen 3.0 002 model', description='Vertex served Imagen 3.0 002 model', version='002', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=480, output_token_limit=8192, supported_actions=['predict'])]\n"
     ]
    },
    {
     "ename": "ClientError",
     "evalue": "404 NOT_FOUND. {'error': {'code': 404, 'message': 'models/text-multilingual-embedding-002 is not found for API version v1beta, or is not supported for embedContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 30\u001b[0m\n\u001b[0;32m     16\u001b[0m         vector \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39membeddings[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m     18\u001b[0m         db\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m     19\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marticles\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     20\u001b[0m             [{\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m             }]\n\u001b[0;32m     27\u001b[0m         )\n\u001b[1;32m---> 30\u001b[0m \u001b[43msave_constitution\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[35], line 12\u001b[0m, in \u001b[0;36msave_constitution\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m chapter_header \u001b[38;5;241m=\u001b[39m article[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchapter\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# more about this on https://ai.google.dev/gemini-api/docs/embeddings#python\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membed_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtitle_header\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mchapter_header\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43marticle_text\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m vector \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39membeddings[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m     18\u001b[0m db\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marticles\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     20\u001b[0m     [{\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m     }]\n\u001b[0;32m     27\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\hahouari\\anaconda3\\envs\\rag_course\\Lib\\site-packages\\google\\genai\\models.py:3972\u001b[0m, in \u001b[0;36mModels.embed_content\u001b[1;34m(self, model, contents, config)\u001b[0m\n\u001b[0;32m   3969\u001b[0m request_dict \u001b[38;5;241m=\u001b[39m _common\u001b[38;5;241m.\u001b[39mconvert_to_dict(request_dict)\n\u001b[0;32m   3970\u001b[0m request_dict \u001b[38;5;241m=\u001b[39m _common\u001b[38;5;241m.\u001b[39mencode_unserializable_types(request_dict)\n\u001b[1;32m-> 3972\u001b[0m response_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_api_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3973\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\n\u001b[0;32m   3974\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3976\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_api_client\u001b[38;5;241m.\u001b[39mvertexai:\n\u001b[0;32m   3977\u001b[0m   response_dict \u001b[38;5;241m=\u001b[39m _EmbedContentResponse_from_vertex(\n\u001b[0;32m   3978\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_api_client, response_dict\n\u001b[0;32m   3979\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\hahouari\\anaconda3\\envs\\rag_course\\Lib\\site-packages\\google\\genai\\_api_client.py:455\u001b[0m, in \u001b[0;36mApiClient.request\u001b[1;34m(self, http_method, path, request_dict, http_options)\u001b[0m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    447\u001b[0m     http_method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    450\u001b[0m     http_options: HttpOptionsOrDict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    451\u001b[0m ):\n\u001b[0;32m    452\u001b[0m   http_request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request(\n\u001b[0;32m    453\u001b[0m       http_method, path, request_dict, http_options\n\u001b[0;32m    454\u001b[0m   )\n\u001b[1;32m--> 455\u001b[0m   response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    456\u001b[0m   json_response \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson\n\u001b[0;32m    457\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m json_response:\n",
      "File \u001b[1;32mc:\\Users\\hahouari\\anaconda3\\envs\\rag_course\\Lib\\site-packages\\google\\genai\\_api_client.py:390\u001b[0m, in \u001b[0;36mApiClient._request\u001b[1;34m(self, http_request, stream)\u001b[0m\n\u001b[0;32m    386\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[0;32m    387\u001b[0m       response\u001b[38;5;241m.\u001b[39mheaders, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response\u001b[38;5;241m.\u001b[39mtext]\n\u001b[0;32m    388\u001b[0m   )\n\u001b[0;32m    389\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 390\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request_unauthorized\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hahouari\\anaconda3\\envs\\rag_course\\Lib\\site-packages\\google\\genai\\_api_client.py:413\u001b[0m, in \u001b[0;36mApiClient._request_unauthorized\u001b[1;34m(self, http_request, stream)\u001b[0m\n\u001b[0;32m    404\u001b[0m http_session \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mSession()\n\u001b[0;32m    405\u001b[0m response \u001b[38;5;241m=\u001b[39m http_session\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[0;32m    406\u001b[0m     method\u001b[38;5;241m=\u001b[39mhttp_request\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    407\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttp_request\u001b[38;5;241m.\u001b[39murl,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    411\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m    412\u001b[0m )\n\u001b[1;32m--> 413\u001b[0m \u001b[43merrors\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAPIError\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[0;32m    415\u001b[0m     response\u001b[38;5;241m.\u001b[39mheaders, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response\u001b[38;5;241m.\u001b[39mtext]\n\u001b[0;32m    416\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\hahouari\\anaconda3\\envs\\rag_course\\Lib\\site-packages\\google\\genai\\errors.py:100\u001b[0m, in \u001b[0;36mAPIError.raise_for_response\u001b[1;34m(cls, response)\u001b[0m\n\u001b[0;32m     98\u001b[0m status_code \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus_code\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m400\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m status_code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m500\u001b[39m:\n\u001b[1;32m--> 100\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m ClientError(status_code, response)\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;241m500\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m status_code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m600\u001b[39m:\n\u001b[0;32m    102\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m ServerError(status_code, response)\n",
      "\u001b[1;31mClientError\u001b[0m: 404 NOT_FOUND. {'error': {'code': 404, 'message': 'models/text-multilingual-embedding-002 is not found for API version v1beta, or is not supported for embedContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}"
     ]
    }
   ],
   "source": [
    "client = genai.Client(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "embed_model_name = \"embedding-001\"\n",
    "\n",
    "print(list(client))\n",
    "\n",
    "def save_constitution():\n",
    "    for article in constitution_data:\n",
    "        article_text = article['article']\n",
    "        title_header = article['title']\n",
    "        chapter_header = article['chapter']\n",
    "        # more about this on https://ai.google.dev/gemini-api/docs/embeddings#python\n",
    "        response = client.models.embed_content(\n",
    "            model=embed_model_name,\n",
    "            contents=f\"{title_header}: {chapter_header}: {article_text}\",  \n",
    "        )\n",
    "        vector = response.embeddings[0].values\n",
    "\n",
    "        db.insert(\n",
    "            \"articles\",\n",
    "            [{\n",
    "                \"text\": article_text,\n",
    "                \"embed_vector\": vector,\n",
    "                \"chapter\": chapter_header,\n",
    "                \"title\": title_header,\n",
    "                \"edition\": datetime(2020, 11, 1).strftime('%Y-%m-%dT%H:%M:%SZ'),\n",
    "            }]\n",
    "        )\n",
    "\n",
    "\n",
    "save_constitution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test Search in Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"score\": 0.21770371660865162,\n",
      "    \"text\": \"المادة 29 : تمتنع الجزائر عن اللّجوء إلى الحرب من أجل المساس بالسّيادة المشروعة للشّعوب الأخرى وحرّيّتها. وتبذل جهدها لتسوية الخلافات الدّوليّة بالوسائل السّلميّة.\"\n",
      "  },\n",
      "  {\n",
      "    \"score\": 0.1928271882325211,\n",
      "    \"text\": \"المادة 169 : الحقّ في الدّفاع معترف به. الحقّ في الدّفاع مضمون في القضايا الجزائيّة.\"\n",
      "  },\n",
      "  {\n",
      "    \"score\": 0.18120915981811977,\n",
      "    \"text\": \"المادة 28 : تنتظم الطّاقة الدّفاعيّة للأمّة، ودعمها، وتطويرها، حول الجيش الوطنيّ الشّعبيّ. تتمثّل المهمّة الدّائمة للجيش الوطنيّ الشّعبيّ في المحافظة على الاستقلال الوطنيّ، والدّفاع عن السّيادة الوطنيّة. كما يضطلع بالدّفاع عن وحدة البلاد، وسلامتها التّرابيّة، وحماية مجالها البرّيّ والجوّيّ، ومختلف مناطق أملاكها البحريّة.\"\n",
      "  },\n",
      "  {\n",
      "    \"score\": 0.1785322494551577,\n",
      "    \"text\": \"المادة 71  : الحقّ في الإضراب مُعترَف به، ويُمارَس في إطار القانون. يمكن أن يمنع القانون ممارسة هذا الحقّ، أو يجعل حدودا لممارسته في ميادين الدّفاع الوطنيّ والأمن، أو في جميع الخدمات أو الأعمال العموميّة ذات المنفعة الحيويّة للمجتمع.\"\n",
      "  },\n",
      "  {\n",
      "    \"score\": 0.17560297801946537,\n",
      "    \"text\": \"المادة 106 : يحدّد تنظيم حالة الطّوارئ وحالة الحصار بموجب قانون عضويّ.\"\n",
      "  },\n",
      "  {\n",
      "    \"score\": 0.17261507899986056,\n",
      "    \"text\": \"المادة 110 : يُوقَف العمل بالدّستور مدّة حالة الحرب ويتولّى رئيس الجمهوريّة جميع السّلطات. وإذا انتهت المدّة الرّئاسيّة لرئيس الجمهوريّة تمدّد وجوبا إلى غاية نهاية الحرب. في حالة استقالة رئيس الجمهوريّة أو وفاته أو حدوث أيّ مانع آخر له، يخوّل رئيس مجلس الأمّة باعتباره رئيسا للدّولة، كلّ الصّلاحيّات الّتي تستوجبها حالة الحرب، حسب الشّروط نفسها الّتي تسري على رئيس الجمهوريّة. في حالة اقتران شغور رئاسة الجمهوريّة ورئاسة مجلس الأمّة، يتولّى رئيس المجلس الدّستوريّ وظائف رئيس الدّولة حسب الشّروط المبيّنة سابقا.\"\n",
      "  },\n",
      "  {\n",
      "    \"score\": 0.17106033696771733,\n",
      "    \"text\": \"المادة 105 : يقرّر رئيس الجمهوريّة، إذا دعت الضّرورة الملحّة، حالة الطّوارئ أو الحصار، لمدّة معيّنة بعد اجتماع المجلس الأعلى للأمن، واستشارة رئيس مجلس الأمة، ورئيس المجلس الشعبي الوطني، والوزير الأول،  ورئيس المجلس الدّستوريّ، ويتّخذ كلّ التّدابير اللاّزمة لاستتباب الوضع. ولا يمكن تمديد حالة الطّوارئ  أو الحصار، إلاّ بعد موافقة البرلمان المنعقد بغرفتيه المجتمعتين معا.\"\n",
      "  },\n",
      "  {\n",
      "    \"score\": 0.1671663042317449,\n",
      "    \"text\": \"المادة 75  : يجب على كلّ مواطن أن يحمي ويصون استقلال البلاد وسيادتها وسلامة ترابها الوطنيّ ووحدة شعبها وجميع رموز الدّولة. يعاقب القانون بكلّ صرامة على الخيانة والتّجسّس والولاء للعدوّ، وعلى جميع الجرائم المرتكَبة ضدّ أمن الدّولة.\"\n",
      "  },\n",
      "  {\n",
      "    \"score\": 0.1621105402208713,\n",
      "    \"text\": \"المادة 158 : أساس القضاء مبادئ الشّرعيّة والمساواة. الكلّ سواسية أمام القضاء، وهو في متناول الجميع ويجسّده احترام القانون.\"\n",
      "  },\n",
      "  {\n",
      "    \"score\": 0.156406640761054,\n",
      "    \"text\": \"المادة 109 : إذا وقع عُدوان فعليّ على البلاد أو يوشك أن يقع حسبما نصّت عليه التّرتيبات الملائمة لميثاق الأمم المتّحدة، يُعلِن رئيس الجمهوريّة الحرب، بعد اجتماع مجلس الوزراء والاستماع إلى المجلس الأعلى للأمن واستشارة رئيس مجلس الأمة ورئيس المجلس الشّعبيّ الوطنيّ ورئيس المجلس الدستوري. ويجتمع البرلمان وجوبا. ويوجّه رئيس الجمهوريّة خطابا للأمّة يُعلِمُها بذلك.\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# user_question = \"worshiping in Algeria\"\n",
    "user_question = \"Qu'est-ce que je peux faire dans la guerre?\"\n",
    "\n",
    "response = client.embeddings.create(\n",
    "    input=user_question,\n",
    "    model=embed_model_name,\n",
    ")\n",
    "q_vector = response.data[0].embedding\n",
    "\n",
    "results = db.query(\"SELECT text, vector::similarity::cosine(embed_vector, $q_vector) AS score FROM articles ORDER BY score DESC LIMIT 10\", {\"q_vector\": q_vector})\n",
    "\n",
    "print(json.dumps(results, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
